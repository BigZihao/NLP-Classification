{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Classification \n",
    "This is an initiative NLP classification that Mike and I have. We plan to automatically classfify variable names of the output from AMP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Predicted', 'EXCLUDE'),\n",
       " ('Category - Can.Volume Sales - Drug', 'Category'),\n",
       " ('Category - Can.Volume Sales - Food', 'Category'),\n",
       " ('SNACKS.PR Impressions', 'PR')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/zihao.zhang/NLP initiative with Mike/variable classification.csv')\n",
    "text = df[['Variable', 'Grouping 2']].apply(tuple, axis=1)\n",
    "text = [i for i in text]\n",
    "text[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the sample data to training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = text[0:900]\n",
    "test = text[-30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "\n",
    "Naive Bayesian Classifier. The idea is based on this package: https://textblob.readthedocs.io/en/dev/classifiers.html#classifying-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction accuracy is actually pretty bad, only 30%. \n",
    "\n",
    "We will take a deeper look how's the model works so that we can improve it. The below code shows how this model works. \n",
    "\n",
    "Naive Bayesian is simple model, basically it is detecting the important words in each class considering their frequecy in training data. \n",
    "\n",
    "So in data process, we need to automatically delete those word with no information. For example, the following shows the model would predict trade when sees 2016. This should be avoid in future modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "contains(Diamond.Market) = False           Trade : Interc =     92.3 : 1.0\n",
      "         contains(Dummy) = False           Trade : Interc =     92.3 : 1.0\n",
      "          contains(Blue) = False           Trade : Interc =     92.3 : 1.0\n",
      "         contains(Merch) = True           Compet : Trade  =     74.0 : 1.0\n",
      "          contains(2016) = True           Hurric : Trade  =     37.7 : 1.0\n",
      "           contains(Oct) = True           Hurric : Trade  =     37.7 : 1.0\n",
      "            contains(v2) = True           Compet : Trade  =     24.5 : 1.0\n",
      "          contains(Week) = True           Distri : Season =     19.5 : 1.0\n",
      "        contains(BDG-SS) = True           Hurric : Trade  =     16.1 : 1.0\n",
      "          contains(Bags) = True           Actual : FSIs   =     15.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at which part the model didn't predict well. The following tuple shows the prediiton. The last column is predicted class while the second column is true class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SNACKS.Twitter Costs Variable', 'Social Media', 'Seasonality'),\n",
       " ('SNACKS.Facebook Costs Variable', 'Social Media', 'Seasonality'),\n",
       " ('BLUE DIAMOND GROWERS-RFG ALM.TPR %ACV - Discount', 'Trade', 'Trade'),\n",
       " ('SNACKS.Facebook Costs Variable', 'Social Media', 'Seasonality'),\n",
       " ('SNACKS.Instagram Costs Variable', 'Social Media', 'Seasonality'),\n",
       " ('SNACKS.Facebook Costs per Imp Variable', 'Social Media', 'Seasonality'),\n",
       " (\"SNACKS - CANS.Walmart May '16 Rollback\", 'Trade', 'Trade'),\n",
       " (\"SNACKS - BAGS.Walmart April'16 25oz Rollback\", 'Trade', 'Trade'),\n",
       " (\"SNACKS - BAGS.Walmart June '16 14oz Rollback\", 'Trade', 'Trade'),\n",
       " ('Easter.Dummy', 'Seasonality', 'Trade'),\n",
       " ('July 4th.Dummy (WMT)', 'Seasonality', 'Seasonality'),\n",
       " ('Memorial Day.Dummy (WMT)', 'Seasonality', 'Seasonality'),\n",
       " ('Snacks - CANS.Rollback May-July', 'Trade', 'Seasonality'),\n",
       " ('Custom Var Holiday Down - WMT Breeze.2016 Holiday Down',\n",
       "  'Seasonality',\n",
       "  'Seasonality'),\n",
       " (\"ASEPTIC.Rollback Feb-April '16\", 'Trade', 'Trade'),\n",
       " ('ALMOND BREEZE - ANY ALMOND BREEZE.Digital Coupon Circulation',\n",
       "  'Digital Coupons',\n",
       "  'FSIs'),\n",
       " ('ALMOND BREEZE - CHILLED ONLY.Digital Coupon Circulation',\n",
       "  'Digital Coupons',\n",
       "  'FSIs'),\n",
       " ('SNACKS - BAGS.Base Price (Volume) v4', 'Base Price', 'Trade'),\n",
       " ('SNACKS - CANS & BAGS.Digital Coupon Circulation',\n",
       "  'Digital Coupons',\n",
       "  'FSIs'),\n",
       " ('SNACKS - CANS ONLY.Digital Coupon Circulation', 'Digital Coupons', 'FSIs'),\n",
       " ('Snacks.Branded', 'Paid Search', 'Trade'),\n",
       " ('Snacks.Competitive', 'Paid Search', 'Trade'),\n",
       " ('Snacks.General', 'Paid Search', 'Trade'),\n",
       " ('SNACKS - BAGS.Any Merch Volume v2', 'Trade', 'Trade'),\n",
       " ('ALMOND BREEZE - ASEPTIC ONLY.Digital Coupon circulation',\n",
       "  'Digital Coupons',\n",
       "  'FSIs'),\n",
       " ('Almond Breeze.Branded', 'Paid Search', 'Seasonality'),\n",
       " ('Almond Breeze.Competitive', 'Paid Search', 'Seasonality'),\n",
       " ('SNACKS - NEW TOTAL.Digital Coupon Circulation ', 'Digital Coupons', 'FSIs'),\n",
       " ('ALMOND BREEZE - NO CHILLED.Digital Coupon Circulation',\n",
       "  'Digital Coupons',\n",
       "  'FSIs'),\n",
       " ('SNACKS - NEW TOTAL.Digital Coupon Circulation ', 'Digital Coupons', 'FSIs')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(test[i][0],test[i][1],cl.classify(test[i][0])) for i in  np.arange(30)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future work\n",
    "\n",
    "In summary, Naive Bayesian is not a good model, it only consider words independently. It is hardly a realy NLP model. But this is a good pipline for us to keep developing more advanced model. \n",
    "\n",
    "To be continued "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
